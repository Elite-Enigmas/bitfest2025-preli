{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10263401,"sourceType":"datasetVersion","datasetId":6349274}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:03:15.242203Z","iopub.execute_input":"2024-12-21T16:03:15.242673Z","iopub.status.idle":"2024-12-21T16:03:15.251082Z","shell.execute_reply.started":"2024-12-21T16:03:15.242629Z","shell.execute_reply":"2024-12-21T16:03:15.250120Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/kuet-preli-1/my_fav_recipes.txt\n","output_type":"stream"}],"execution_count":200},{"cell_type":"code","source":"pip install -U langchain-community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:03:15.259961Z","iopub.execute_input":"2024-12-21T16:03:15.260210Z","iopub.status.idle":"2024-12-21T16:03:18.616056Z","shell.execute_reply.started":"2024-12-21T16:03:15.260188Z","shell.execute_reply":"2024-12-21T16:03:18.614898Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.13)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.35)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.5)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\nRequirement already satisfied: langchain<0.4.0,>=0.3.13 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.13)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.28)\nRequirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.4)\nRequirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.7.0)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.13->langchain-community) (0.3.4)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.13->langchain-community) (2.9.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (24.1)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.12)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain-community) (2.23.4)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.2.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":201},{"cell_type":"code","source":"pip install langchain transformers faiss-gpu sentence-transformers torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:03:18.617586Z","iopub.execute_input":"2024-12-21T16:03:18.617884Z","iopub.status.idle":"2024-12-21T16:03:21.857687Z","shell.execute_reply.started":"2024-12-21T16:03:18.617860Z","shell.execute_reply":"2024-12-21T16:03:21.856639Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.13)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nRequirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.26 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.28)\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.4)\nRequirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.4)\nRequirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (1.33)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.26->langchain) (3.0.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":202},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\n\n\ndef load_and_cache_model(model_name: str, cache_dir: str = \"./model_cache\"):\n    \"\"\"\n    Load and cache the model and tokenizer locally.\n    \"\"\"\n    print(f\"Loading model '{model_name}' locally...\")\n    tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n    model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=cache_dir, device_map=\"auto\")\n    print(f\"Model '{model_name}' loaded successfully.\")\n    return tokenizer, model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:03:21.859323Z","iopub.execute_input":"2024-12-21T16:03:21.859576Z","iopub.status.idle":"2024-12-21T16:03:21.864972Z","shell.execute_reply.started":"2024-12-21T16:03:21.859553Z","shell.execute_reply":"2024-12-21T16:03:21.863993Z"}},"outputs":[],"execution_count":203},{"cell_type":"code","source":"from langchain.text_splitter import RecursiveCharacterTextSplitter\n\ndef split_documents(documents):\n    \"\"\"\n    Split documents into manageable chunks using LangChain's splitter.\n    \"\"\"\n    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n    split_docs = text_splitter.split_documents(documents)\n    return split_docs\ndef clean_response(response):\n    \"\"\"\n    Remove unrelated or redundant content from the model's response.\n    \"\"\"\n    # Keep only the recipe section by identifying structure\n    recipe_start = response.find(\"Name:\")\n    if recipe_start != -1:\n        response = response[recipe_start:]\n\n    return response.strip()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:03:21.866219Z","iopub.execute_input":"2024-12-21T16:03:21.866478Z","iopub.status.idle":"2024-12-21T16:03:21.882607Z","shell.execute_reply.started":"2024-12-21T16:03:21.866447Z","shell.execute_reply":"2024-12-21T16:03:21.881833Z"}},"outputs":[],"execution_count":204},{"cell_type":"code","source":"from langchain.schema import Document\n\ndef parse_recipes(file_path: str):\n    \"\"\"\n    Parse recipes from the text file into LangChain Document objects.\n    \"\"\"\n    with open(file_path, \"r\") as file:\n        content = file.read()\n\n    # Split recipes by \"# Recipe\"\n    raw_recipes = content.split(\"# Recipe\")\n    documents = []\n\n    for raw_recipe in raw_recipes:\n        raw_recipe = raw_recipe.strip()\n        if not raw_recipe:\n            continue\n        documents.append(Document(page_content=raw_recipe))\n    \n    return documents\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import FAISS\n\ndef create_vectorstore(documents):\n    \"\"\"\n    Create a FAISS vector store for efficient retrieval.\n    \"\"\"\n    # Use Hugging Face embeddings\n    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n    \n    # Create FAISS index from documents\n    vectorstore = FAISS.from_documents(documents, embeddings)\n    return vectorstore\n\ndef retrieve_relevant_documents(query, vectorstore, top_k=3):\n    \"\"\"\n    Retrieve the most relevant documents for a given query.\n    \"\"\"\n    docs = vectorstore.similarity_search(query, k=top_k)\n    return docs\ndef create_rag_prompt(relevant_docs, query, max_recipes=2):\n    \"\"\"\n    Create a prompt with the most relevant recipes for the user's query.\n    \"\"\"\n    # Use only the top relevant recipes\n    relevant_text = \"\\n\\n\".join([doc.page_content.strip() for doc in relevant_docs[:max_recipes]])\n    \n    # Structured prompt\n    prompt = (\n        f\"Here are the most relevant recipes based on your query:\\n\\n\"\n        f\"{relevant_text}\\n\\n\"\n        f\"User Query: {query}\\n\\n\"\n        f\"Provide a single complete recipe that matches the query without including irrelevant information.\"\n    )\n    return prompt\n\n\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\ndef generate_rag_response(prompt, tokenizer, model):\n    \"\"\"\n    Generate a response using the RAG pipeline.\n    \"\"\"\n    # Tokenize the input\n    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # Generate the output\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=150,\n        do_sample=True,\n        temperature=0.7,\n        top_k=50,\n        top_p=0.9,\n        pad_token_id=tokenizer.eos_token_id\n    )\n\n    # Decode the output\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n    return response\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:03:21.883470Z","iopub.execute_input":"2024-12-21T16:03:21.883689Z","iopub.status.idle":"2024-12-21T16:03:21.897702Z","shell.execute_reply.started":"2024-12-21T16:03:21.883668Z","shell.execute_reply":"2024-12-21T16:03:21.897090Z"}},"outputs":[],"execution_count":205},{"cell_type":"code","source":"def query_local_llm(query, vectorstore, tokenizer, model, max_recipes=2):\n    \"\"\"\n    Query the local LLM with retrieved recipes, ensuring concise and relevant output.\n    \"\"\"\n    # Retrieve relevant documents\n    docs = vectorstore.similarity_search(query, k=max_recipes)\n    if not docs:\n        return \"No relevant recipes found.\"\n\n    # Create a structured and focused prompt\n    prompt = create_rag_prompt(docs, query)\n\n    # Tokenize the prompt\n    inputs = tokenizer(\n        prompt, \n        return_tensors=\"pt\", \n        truncation=True, \n        max_length=1024\n    ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # Generate the response\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=1500,  # Limit response length\n        do_sample=True,\n        temperature=0.7,\n        top_k=50,\n        top_p=0.9,\n        pad_token_id=tokenizer.eos_token_id\n    )\n\n    # Decode and clean the response\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n\n    return response\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:03:21.898423Z","iopub.execute_input":"2024-12-21T16:03:21.898701Z","iopub.status.idle":"2024-12-21T16:03:21.916323Z","shell.execute_reply.started":"2024-12-21T16:03:21.898669Z","shell.execute_reply":"2024-12-21T16:03:21.915549Z"}},"outputs":[],"execution_count":206},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import FAISS\nfrom langchain.chains import LLMChain\nfrom langchain.prompts import PromptTemplate\nfrom langchain.llms import HuggingFaceHub\n\ndef load_recipes(file_path: str):\n    \"\"\"\n    Load recipes from a text file and prepare them as documents.\n    \"\"\"\n    loader = TextLoader(file_path)\n    documents = loader.load()\n    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n    split_docs = text_splitter.split_documents(documents)\n    return split_docs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:03:21.917093Z","iopub.execute_input":"2024-12-21T16:03:21.917324Z","iopub.status.idle":"2024-12-21T16:03:21.933508Z","shell.execute_reply.started":"2024-12-21T16:03:21.917304Z","shell.execute_reply":"2024-12-21T16:03:21.932645Z"}},"outputs":[],"execution_count":207},{"cell_type":"code","source":"def create_vectorstore(documents):\n    \"\"\"\n    Create a FAISS vector store from the recipe documents.\n    \"\"\"\n    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n    vectorstore = FAISS.from_documents(documents, embeddings)\n    return vectorstore\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:03:21.936116Z","iopub.execute_input":"2024-12-21T16:03:21.936339Z","iopub.status.idle":"2024-12-21T16:03:21.947633Z","shell.execute_reply.started":"2024-12-21T16:03:21.936320Z","shell.execute_reply":"2024-12-21T16:03:21.946968Z"}},"outputs":[],"execution_count":208},{"cell_type":"code","source":"def create_prompt():\n    \"\"\"\n    Create a prompt template for the LLM to suggest recipes.\n    \"\"\"\n    return PromptTemplate(\n        input_variables=[\"relevant_docs\", \"query\"],\n        template=\"Relevant recipes:\\n{relevant_docs}\\n\\nUser Query: {query}\\nAnswer:\"\n    )\n\ndef query_llm(query, vectorstore, llm):\n    \"\"\"\n    Query the LLM with relevant recipes based on the user's query.\n    \"\"\"\n    # Retrieve relevant documents\n    docs = vectorstore.similarity_search(query, k=3)\n    relevant_docs = \"\\n\".join([doc.page_content for doc in docs])\n\n    # Use LangChain LLMChain to generate a response\n    prompt = create_prompt()\n    chain = LLMChain(prompt=prompt, llm=llm)\n    response = chain.run(relevant_docs=relevant_docs, query=query)\n    return response\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:03:21.948822Z","iopub.execute_input":"2024-12-21T16:03:21.949162Z","iopub.status.idle":"2024-12-21T16:03:21.961921Z","shell.execute_reply.started":"2024-12-21T16:03:21.949102Z","shell.execute_reply":"2024-12-21T16:03:21.960999Z"}},"outputs":[],"execution_count":209},{"cell_type":"code","source":"def retrieve_relevant_recipes(query, vectorstore, top_k=3):\n    \"\"\"\n    Retrieve the most relevant recipes for a given query.\n    \"\"\"\n    results = vectorstore.similarity_search(query, k=top_k)\n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:03:21.962901Z","iopub.execute_input":"2024-12-21T16:03:21.963282Z","iopub.status.idle":"2024-12-21T16:03:21.979722Z","shell.execute_reply.started":"2024-12-21T16:03:21.963252Z","shell.execute_reply":"2024-12-21T16:03:21.979112Z"}},"outputs":[],"execution_count":210},{"cell_type":"code","source":"from langchain.prompts import PromptTemplate\nfrom langchain.chains import RetrievalQA\nfrom langchain.llms import HuggingFacePipeline\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n\ndef create_retrieval_chain(vectorstore, model_name=\"EleutherAI/gpt-neo-1.3B\"):\n    \"\"\"\n    Create a RetrievalQA chain using a local LLM and vectorstore.\n    \"\"\"\n    # Load the model locally\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n    hf_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)\n\n    # Define the prompt template\n    prompt_template = PromptTemplate(\n        input_variables=[\"context\", \"question\"],\n        template=\"Context:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n    )\n\n    # Create RetrievalQA chain\n    qa_chain = RetrievalQA.from_chain_type(\n        llm=HuggingFacePipeline(pipeline=hf_pipeline),\n        retriever=vectorstore.as_retriever(),\n        return_source_documents=True,\n        chain_type_kwargs={\"prompt\": prompt_template}\n    )\n\n    return qa_chain\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:03:21.980480Z","iopub.execute_input":"2024-12-21T16:03:21.980704Z","iopub.status.idle":"2024-12-21T16:03:21.996922Z","shell.execute_reply.started":"2024-12-21T16:03:21.980683Z","shell.execute_reply":"2024-12-21T16:03:21.996189Z"}},"outputs":[],"execution_count":211},{"cell_type":"code","source":"def extract_first_recipe_block(response):\n    \"\"\"\n    Extracts the content from the first '#' and terminates at the second '#',\n    skipping the '#' line itself.\n    \"\"\"\n    lines = response.splitlines()\n    start_collecting = False\n    collected_lines = []\n\n    for line in lines:\n        if line.startswith(\"#\"):\n            if start_collecting:  # If a second '#' is found, stop collecting\n                break\n            start_collecting = True  # Start collecting after the first '#'\n            continue  # Skip the '#' line itself\n        if start_collecting:\n            collected_lines.append(line.strip())  # Collect non-empty lines\n\n    return \"\\n\".join(collected_lines)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:03:21.997638Z","iopub.execute_input":"2024-12-21T16:03:21.997863Z","iopub.status.idle":"2024-12-21T16:03:22.007980Z","shell.execute_reply.started":"2024-12-21T16:03:21.997843Z","shell.execute_reply":"2024-12-21T16:03:22.007113Z"}},"outputs":[],"execution_count":212},{"cell_type":"code","source":"def main():\n    # File path to recipes\n    file_path = \"/kaggle/input/kuet-preli-1/my_fav_recipes.txt\"\n\n    # Load, split, and index recipes\n    documents = load_recipes(file_path)\n    split_docs = split_documents(documents)\n    vectorstore = create_vectorstore(split_docs)\n\n    # Load the model\n    MODEL_NAME = \"EleutherAI/gpt-neo-1.3B\"\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"auto\")\n\n    # User query\n    query = \"Suggest a quick dinner recipe with chicken and broccoli.\"\n\n    # Get response from the LLM\n    response = query_local_llm(query, vectorstore, tokenizer, model)\n    cleaned_response = extract_first_recipe_block(response)\n\n    # Print the final response\n    print(f\"Generated Recipe:\\n{cleaned_response}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:03:22.008839Z","iopub.execute_input":"2024-12-21T16:03:22.009085Z","iopub.status.idle":"2024-12-21T16:03:22.021568Z","shell.execute_reply.started":"2024-12-21T16:03:22.009053Z","shell.execute_reply":"2024-12-21T16:03:22.020721Z"}},"outputs":[],"execution_count":213},{"cell_type":"code","source":"main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:03:22.022495Z","iopub.execute_input":"2024-12-21T16:03:22.022795Z","iopub.status.idle":"2024-12-21T16:04:02.972359Z","shell.execute_reply.started":"2024-12-21T16:03:22.022762Z","shell.execute_reply":"2024-12-21T16:04:02.971451Z"}},"outputs":[{"name":"stdout","text":"Generated Recipe:\nName: Vegetable Stir Fry\nIngredients: Broccoli: 1 head, Bell Peppers: 2 medium, Carrots: 2 medium, Soy Sauce: 2 tbsp, Garlic: 3 cloves, Ginger: 1 inch piece, grated\nTaste: Savory\nCuisine: Asian\nPreparation Time: 20\nInstructions:\n1. Heat oil in a wok.\n2. Add garlic and ginger, and stir-fry for 1 minute.\n3. Add vegetables and stir-fry for 5 minutes.\n4. Add soy sauce, cook for another 2 minutes, and serve.\n\n","output_type":"stream"}],"execution_count":214},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}